{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2019 OERCompBiomed (UiB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short \"get-started\" to object recognition in computer vision\n",
    "\n",
    "###  \"Hello World 3\" (PatchCamelyon benchmark) using TF 2 / [Keras](https://www.tensorflow.org/beta/guide/keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Object recognition** is a general term to describe a collection of related computer vision tasks that involve identifying objects in digital images. In this notebook we will consider the task:\n",
    "\n",
    "- **Image Classification**: Predict the type or class of an object in an image.\n",
    "  - *Input*: An image with a single object, such as a photograph or a medical image.\n",
    "  - *Output*: A class label (e.g. one or more integers that are mapped to class labels).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also:<br>\n",
    " https://www.tensorflow.org/beta/guide/keras/training_and_evaluation  and <br>\n",
    " Keras ResNet(18,34,50,101,152) pre-trained models https://github.com/qubvel/classification_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TO DO**\n",
    "\n",
    "\n",
    "https://github.com/basveeling/pcam - The PatchCamelyon benchmark is a new and challenging image classification dataset. It consists of 327.680 color images (96 x 96px) extracted from histopathologic scans of lymph node sections. Each image is annoted with a binary label indicating presence of metastatic tissue. PCam provides a new benchmark for machine learning models: bigger than CIFAR10, smaller than imagenet, trainable on a single GPU.\n",
    "\n",
    "combined with https://github.com/nickbiso/Keras-Class-Activation-Map - A \"class activation\" heatmap is a 2D grid of scores associated with an specific output class, computed for every location in any input image, indicating how important each location is with respect to the class considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SEILI",
   "language": "python",
   "name": "seili"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
